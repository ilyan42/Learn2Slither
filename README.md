# Learn2Slither

**Reinforcement Learning** - Un serpent qui apprend Ã  se comporter dans un environnement par essai-erreur.

# Description

Ce projet implÃ©mente un agent intelligent contrÃ´lant un serpent sur un plateau de jeu 10x10. L'agent utilise l'algorithme **Q-Learning** pour apprendre Ã  :
- Manger les pommes vertes
- Ã‰viter les pommes rouges
- Ã‰viter les murs et son propre corps
- Survivre le plus longtemps possible

**Objectif** : Atteindre une longueur de **10 ou plus** et survivre le plus longtemps possible.

## ğŸ—ï¸ Structure du Projet

```
Learn2Slither/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e principal
â”œâ”€â”€ Board/
â”‚   â””â”€â”€ environment.py      # Environnement du jeu (plateau, snake, pommes)
â”œâ”€â”€ agent/
â”‚   â””â”€â”€ agent.py            # Agent Q-Learning (Q-table, actions, rewards)
â”œâ”€â”€ modes/
â”‚   â””â”€â”€ game_modes.py       # Modes de jeu (train, evaluate, visual)
â”œâ”€â”€ render/
â”‚   â”œâ”€â”€ display.py          # Affichage graphique Pygame
â”‚   â””â”€â”€ ascii.py            # Affichage ASCII terminal
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ io.py               # Sauvegarde/chargement des modÃ¨les
â””â”€â”€ models/                 # ModÃ¨les entraÃ®nÃ©s
    â”œâ”€â”€ 1sess.pkl
    â”œâ”€â”€ 10sess.pkl
    â”œâ”€â”€ 100sess.pkl
    â”œâ”€â”€ 5000sess.pkl
    â”œâ”€â”€ visiononly_20k.pkl
    â””â”€â”€ Snake_3.0.plk
```

# Utilisation

### Mode EntraÃ®nement (`--train`)

EntraÃ®ne un nouveau modÃ¨le avec le nombre d'Ã©pisodes spÃ©cifiÃ©.

```bash
# EntraÃ®ner 100 Ã©pisodes et sauvegarder
python3 main.py --train --episodes 100 --save models/100sess.pkl

# EntraÃ®ner 5000 Ã©pisodes
python3 main.py --train --episodes 5000 --save models/5000sess.pkl

# EntraÃ®ner 50000 Ã©pisodes (recommandÃ© pour de bonnes performances)
python3 main.py --train --episodes 50000 --save models/mon_model.pkl
```

### Mode Ã‰valuation (`--evaluate`)

Ã‰value un modÃ¨le sans apprentissage (mode `dontlearn`).

```bash
# Ã‰valuer sur 100 parties
python3 main.py --evaluate --load models/5000sess.pkl --games 100

# Ã‰valuer le meilleur modÃ¨le
python3 main.py --evaluate --load models/Snake_3.0.plk --games 100

# DÃ©sactiver le filtre de sÃ©curitÃ©
python3 main.py --evaluate --load models/5000sess.pkl --games 100 --no-safety
```

### Mode Visualisation (`--visual`)

Visualise le serpent en action.

```bash
# Visualisation en ASCII (terminal)
python3 main.py --visual --load models/Snake_3.0.plk

# Visualisation avec fenÃªtre graphique Pygame
python3 main.py --visual --load models/Snake_3.0.plk --window

# Ajuster la vitesse (FPS)
python3 main.py --visual --load models/Snake_3.0.plk --window --fps 5

# Mode pas-Ã -pas (appuyer sur ENTRÃ‰E pour avancer)
python3 main.py --visual --load models/Snake_3.0.plk --window --step
```

## âš™ï¸ Arguments

| Argument | Description |
|----------|-------------|
| `--train` | Mode entraÃ®nement |
| `--evaluate` | Mode Ã©valuation (sans apprentissage) |
| `--visual` | Mode visualisation |
| `--load <path>` | Charger un modÃ¨le existant |
| `--save <path>` | Sauvegarder le modÃ¨le entraÃ®nÃ© |
| `--episodes <n>` | Nombre d'Ã©pisodes d'entraÃ®nement (dÃ©faut: 2000) |
| `--games <n>` | Nombre de parties pour l'Ã©valuation (dÃ©faut: 100) |
| `--window` | Affichage graphique Pygame |
| `--fps <n>` | Vitesse d'affichage (dÃ©faut: 10) |
| `--step` | Mode pas-Ã -pas |
| `--no-safety` | DÃ©sactive le filtre de sÃ©curitÃ© |

## ğŸ“Š Performances des ModÃ¨les

Les performances varient en fonction du nombre d'Ã©pisodes d'entraÃ®nement :

| ModÃ¨le | Ã‰pisodes | Ã‰tats Q | Moy. | Max | â‰¥10 |
|--------|----------|---------|------|-----|-----|
| `1sess.pkl` | 1 | 1 | 3.00 | 4 | 0% |
| `10sess.pkl` | 10 | 20 | 3.12 | 4 | 0% |
| `100sess.pkl` | 100 | 164 | 3.18 | 4 | 0% |
| `5000sess.pkl` | 5,000 | 2,046 | 7.68 | 19 | 32% |
| `visiononly_20k.pkl` | 50,000 | 3,543 | 15.14 | 30 | 70% |
| **`Snake_3.0.plk`** | **500,000** | **5,098** | **18.16** | **40** | **76%** |

Remarque : Les modÃ¨les avec peu d'entraÃ®nement (1, 10, 100 sessions) montrent des performances limitÃ©es. C'est normal et dÃ©montre l'importance de l'apprentissage progressif. Pour de bonnes performances, utilisez un modÃ¨le avec **5000+ Ã©pisodes**.

# AmÃ©liorations du State

L'intelligence de l'IA a Ã©tÃ© amÃ©liorÃ©e grÃ¢ce Ã  plusieurs optimisations de la reprÃ©sentation d'Ã©tat :

### Vision du Snake
Le snake voit dans les **4 directions** (UP, RIGHT, DOWN, LEFT) depuis sa tÃªte :
- `G` = Pomme verte
- `R` = Pomme rouge
- `S` = Corps du snake
- `W` = Mur

# Bucketing de Distance
Les distances sont regroupÃ©es en **3 catÃ©gories** pour rÃ©duire l'espace d'Ã©tats :
- `1` = TrÃ¨s proche (1-2 cases)
- `2` = Proche (3-4 cases)
- `3` = Loin (5+ cases)

# Reward Shaping

- Manger pomme verte : +20
- Manger pomme rouge : -20
- Game Over (mur/collision/longueur 0) : -100
- Timeout (trop de steps sans manger) : -50
- Se diriger vers une pomme verte visible : +0.2
- Se diriger vers un danger immÃ©diat : -1.0

## ğŸ¯ Exemples de Commandes

```bash
# Exemple complet : entraÃ®ner, puis Ã©valuer
python3 main.py --train --episodes 10000 --save models/nouveau.pkl
python3 main.py --evaluate --load models/nouveau.pkl --games 100

# Voir le meilleur modÃ¨le en action
python3 main.py --visual --load models/Snake_3.0.plk --window --fps 8

# Mode pas-Ã -pas pour observer chaque dÃ©cision
python3 main.py --visual --load models/Snake_3.0.plk --step
```

